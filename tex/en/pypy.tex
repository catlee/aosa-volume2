\begin{aosachapter}{PyPy}{s:pypy}{Benjamin Peterson}

PyPy is a Python implementation written in Python.

\begin{aosasect1}{A Little History}

Python is high-level, dynamic programming langauge. It was invented by Guido van
Rossum in the late 1980s. The original implementation is a traditional bytecode
interpreter. Since it is written in C, it is called CPython. There are now many
other Python implementations. Among the most notable are Jython, which is
written in Java and allows for interfacing with Java code, IronPython, which is
written in C\# and interfaces with Microsoft's .NET framework, and PyPy, the
subject of this chapter. CPython is still the most widely used implementation
and the only one to support Python 3, the next generation of the Python
language. This chapter will explain the design decisions in PyPy that make it
different from other Python implementations and indeed from any other dynamic
language implementation.

\end{aosasect1}

\begin{aosasect1}{Overview of PyPy}
PyPy, except for a negligible amount of C stubs, is written completely in
Python. The PyPy source tree contains two major components. Firstly, there is
the Python interpreter, which is the user-facing Python runtime that people
using PyPy as a Python implementation invoke. The Python interpreter is actually
written in a subset of Python called Restricted Python (abbreviated
RPython). The purpose of writing the Python interpreter in RPython is that it
can be fed to the second major part of PyPy, the RPython translation
toolchain. The RPython translator takes RPython code and converts it to a
choosen lower level language, most commonly C. This allows PyPy to be a
self-hosting implemention. As we shall see throughout this chapter, it also
makes a general dynamic language implementation framework.

\end{aosasect1}

\begin{aosasect1}{The Python Interpreter}

For the most part, the details of the PyPy Python interpreter are quite similiar
to that of CPython; they use the nearly identical bytecode and data structures
during interpretation. The primary difference between the two is the
introduction of a clever abstraction called \emph{object spaces} (or objspaces
for short). An objspace encapsulates all the knowledge needed to represent and
manipulate Python data types. For example, using a binary operator with objects
or fetching an attribute is handled completely by the objspace. This allows the
interpreter to not know anything about the implementation details of Python
objects. The interpreter treats Python objects as black boxes and calls objspace
methods whenever it needs to use them. For example, here is a rough
implementation of the \verb+BINARY\_ADD+ opcode, which is called when two
objects are combined with +

\begin{verbatim}
def BINARY_ADD(space):
    object1, object2 = # pop 2 values off the stack
    result = space.add(object1, object2)
    # push result onto the stack
\end{verbatim}

The objspace abstraction has numerous advantages. It allows new data type
implementations to be swapped in and out without modifying the
interpreter. Also, since the sole way to manipulate objects is through objspace,
the objspace can intercept, proxy, or record operations on objects. Using the
powerful abstraction of objspaces, PyPy has experimented with are thunking,
where results can be lazily but completely transparently computed on demand, and
tainting, where any operation on a object will raise an exception (useful for
passing sensitive data through untrusted code). The most important application
of objspaces, however, will be discussed under the next section about
translation.

The objspace used in a vanilla PyPy interpreter is called the \emph{standard
  objspace} or std objspace for short. In addition to the abstraction provided
by the objspace system, the std objspace provides another level of indirection;
A single data type may have multiple implementations. Operations on data types
are then dispatched using multimethods. This allows picking the most efficient
representation for a given piece of data. For example, the Python long type
(ostensibly a bigint data type) can be represented as a standard machine word
sized integer when it is small enough, so the memory and computationally less
efficient arbitrary-precision implementation need only be used when
necessary. (There's even an implementation of Python integers available using
tagged pointers.) Container types can also be specialized to certain data
types. For example, PyPy has an dictionary (Python's hash table data type)
implementation specialized for strings keys. The fact that the same data type
can be represented by different implementations is, of course, completely
transparent to application level code; a dictionary specialized to strings is
identical to a generic dictionary and will degenerate gracefully if non-string
keys are put into it.

\end{aosasect1}

\begin{aosasect1}{The RPython Translator}
\label{sec:translator}

The RPython translator is really a toolchain of several lowering phases that
reduce RPython to a target language, typically C. It is itself written in
(unrestricted) Python and intimately linked to the PyPy Python interpreter for
reasons that will be illuminated shortly.

The first thing the translator does is load the RPython program into its
process. (This is done with the normal Python module loading support.) RPython
imposes a set of restrictions on normal, dynamic Python. For example, functions
cannot be created at runtime, and a single variable cannot have the possibility
of holding incompatible types, such as an integer and a object instance. When
the program is loaded by the translator, though, it is running on a normal
Python interpreter and can use all of Python's dynamic features. PyPy's Python
interpreter, a huge RPython program, makes heavy use of this feature. For
example, it generates code for standard objspace multimethod dispatch. The only
requirement is that the program is valid RPython by the time the translator
starts the next phase of translation.

The translator builds flow graphs of the RPython program through a process
called \emph{abstract interpretation}. Abstract interpretation reuses the PyPy
Python interpreter to interpret RPython programs in a special objspace called
the \emph{flow objspace}. Recall, the Python interpreter treats objects in a
program like black boxes, calling out to the objspace to perform any
operation. The flow objspace, instead of the standard set of Python objects, has
only two objects: variables and constants. Variables represent values not known
during translation, and constants, obviously, immutable values that are
known. What is immutable and must be constant in RPython is broader than in
standard Python. For example, modules, which are emphatically mutable in Python,
are constants in the flow objspace because they don't exist in RPython and must
be constant-folded out. As the Python interpreter interprets RPython functions,
the flow objspace records the operations it is asked to perform. It also takes
care to record all branches of conditional control flow constructs. The end
result of abstract interpretation for a function is a flow-graph consisting of
linked blocks.

An example of the flow-graph generating process is in order. Consider a simple
factorial function

\begin{verbatim}
def factorial(n):
    if n == 1:
        return 1
    return n * factorial(n - 1)
\end{verbatim}

The flow-graph for the function looks like \aosafigref{fig.pypy.flowgraph}

\aosafigure{../images/pypy/flowgraph.png}{Flow-graph of factorail}{fig.pypy.flowgraph}

As you can see, the factorial function has been divided into blocks containing
the operations the flowspace recorded. Each block has input arguments and a list
of operations on variables and constants. At the end of the block is a exit
switch, which determines which block control flow will pass to based on the
value of some variable.

Thw flow-graph generated in the flow objspace is in static single assignment
form, or SSA, a intermediate representations commonly used in compilers. The key
feature of SSA is that every variable is only assigned once.

After a function graph is generated, the annotation phase beings. The annotator
assigns a type to the result of each SSA operation. Here is the flow-graph of the
factorial function above after being annotated:

\aosafigure{../images/pypy/flowgraph-annotated.png}{Annotated Flowgraph}{fig.pypy.flowgraph-ann}

The next phase is called RTyping. It is the first part of translation that final
target backend matters. The backend chooses which type system the program is
specialized to. The RTyper currently has two type systems: A low level
typesystem for backends like C and one for higher level typesystems with
classes. RTyping uses type information from the annotator to expand each
high-level flow-graph operation into low-level ones. For example, for an +add+
operation with operands annotated as integers will generate an +int\_add+. More
complication operations like hash table lookups generate function calls.

After Rtyping, some optimizations on the low-level flow-graph are performed. They
are mostly of the traditional compiler variety like constant folding, store
sinking, and dead code removal.

The program, now in optimized, low-level flow-graphs, is passed now to the
backend to generate sources. Before it can generate C code, the C backend has to
do some additional transformations. RPython is a garabage collected language,
but C is not, so a garbage collector has to be added. To do this, a garbage
collector transformer converts the flow-graphs of the program into a garbage
collected program. PyPy's GC transformers provide an excellent demonstration of
how translation abstracts away mundane details. In CPython, which uses reference
counting, the C code of the interpreter has a carefully keep track of references
to Python objects it is manipulating. This not only hardcodes the garbage
collection scheme in the entire codebase but is prone to subtle human
errors. PyPy's GC transformers solve both problems. It allows different garbage
collection schemes to be swaped in and out seamlessly. Modulo transformer bugs,
it also never makes reference mistakes or forgets to inform the GC when an
object is no longer in use. As a result, it is trivial to evaluate the a garbage
collector implementation (of which PyPy has many), simply by tweaking an option
at translation.

\end{aosasect1}

\begin{aosasect1}{The PyPy JIT}

Python, like most dynamic languages, has traditionally traded efficiency for
flexibility. The architecture of PyPy, being especially rich in flexibility and
abstraction, makes very fast interpretation difficult. The power of the objspace
and multimethod abstractions are not without a cost. Consequently, the vanilla
PyPy interpreter peforms up to 4 times than slower CPython. To remedy not only
this but Python's reputation as a slow language, PyPy has a Just-in-time
compiler (commonly just JIT). The JIT compiles frequently used codepaths to
assembly during the runtime of the program.

The PyPy JIT takes advantage PyPy's unique translation architecture described
above. PyPy actually has no \emph{Python-specific} JIT; it has JIT
generator. JIT generation is implemented as simply another optional pass during
translation. A interpreter desiring JIT generation need only make two special
function calls called ``hints''.

PyPy's JIT is a \emph{tracing JIT}. This means it detects ``hot'' (meaning
frequently run) loops to optimize by compiling to assembly. When the JIT has
decided it is going to compile a loop, it records operations in one iteration of
the loop, a process \emph{tracing}. These operations are subsequently compiled
to machine code.

As mentioned above, the JIT generator requires only two hints in the interpreter
to generate a JIT: \verb+merge_point+ and
\verb+can_enter_jit+. \verb+can_enter_jit+ unsurprisingly tells the JIT where in
the interpreter a loop starts. In the Python interpreter, this is the end of the
\verb+JUMP_ABSOLUTE+ bytecode, which occurs at the end of Python \verb+while+
and \verb+for+ loops. \verb+merge_point+ tells the JIT where it is safe to
return to the interpreter. This is the beginning of bytecode dispatch in the
Python interpreter.

The JIT generator is invoked after the RTyping phase of translation. Recall that
at this point, the program's flow-graphs consist of low-level operations nearly
ready for target code generation. The JIT generator locates the hints mentioned
above in the interpreter and replaces them with calls to invoke the JIT during
runtime. The JIT generator then writes a serialized representation of the
flow-graph called a jitcode for every function that the interpreter wants
jitted. The entire interpreter is now described in terms of low-level RPython
operations. The jitcodes are saved in the final binary for use at runtime.

At runtime the JIT maintains a counter for every loop that is executed in the
program. When the loop counter exceeds a configurable threshold, the JIT is
invoked and tracing begins. The key concept in tracing is the
\emph{meta-interpreter}. The meta-interpreter executes the jitcodes created in
translation. It is thus interpreting the main interpreter, hence the name. As it
traces the loop, it creates a list of the operations it is executing and records
them in JIT intermediate representation (IR), another instruction format. The
meta-interpreter is forced to specialize the trace to properties of the current
iteration. For example, when the meta-interpreter encounters a conditional in
the jitcode, it naturally has to choose one path. When it makes a choice based
on runtime information, the meta-interpreter records an IR operation called a
\emph{guard}. In the case of a conditional, this will be a \verb+guard_true+ or
\verb+guard_false+ operation on the condition variable. Another place where
guards are found is arithmetic operations, which will generate overflow guards
for their results. Essentially, guards codify assumptions the meta-interpreter
is making as it traces. When assembly is generated, the guards will protect
assembly being run whose assumptions are not met. Tracing ends when the
meta-interpreter reaches the same \verb+can_enter_jit+ operation that it started
tracing with. The loop IR can now be passed to the optimizer.

The JIT optimizer features a few classical compiler optimizations and many
optimizations specialized for dynamic languages. Among the most important of the
latter are \emph{virtuals} and \emph{virtualizables}. Virtuals are objects which
are known not to escape the trace.

Since the instructional format is already quite low-level, actual assembly
generation is not too difficult. The register allocator is simple; At the
moment, we think the increased time that would be spent in the backend with a
more sophisticated register allocation algorithm in exchange for generating
slightly better code has not been justified. The trickiest portion is garbage
collector support. The GC has to be made aware of stack roots in the generated
JIT code. This is accomplished by special support in the GC for dynamic root
maps.

When a guard fails, the compiled assembly is now longer valid, and control has
to return to the bytecode interpreter. This bailing out is one of the most
difficult parts of JIT implementation, since the interpreter state has to be
reconstructed from the register and stack state at the point the guard
failed. The failing guard may be in the middle of the execution of a complicated
opcode, so the interpreter can't just start with the next opcode. PyPy uses
\emph{blackhole interpreter}. The blackhole interpreter executes jitcodes
starting from the point of guard failure until the next merge point is reached
at which point the real interpreter can resume. Its name comes from the fact
that unlike the meta-interpreter it doesn't record any of the operations it
executes.

How successful have the techniques used in the PyPy JIT proven? At the time of
this writing, PyPy is an (geometric) average of 5 times faster than CPython on a
comprehensive suite of benchmarks.

Most importantly, the fact that the JIT is not specific to Python means it could
be applied to any language interpreter written within the Python framework. It
is already used for Python's regular expression engine.

\end{aosasect1}

\begin{aosasect1}{Design Drawbacks}
\label{sec:drawbacks}

The levels of abstraction are not always are clear cut as in theory. While
technically the JIT generator should be able to produce an excellent JIT for a
language with only the two hints mentioned above, the reality is that it behaves
better on some code than others. The Python interpreter has seen a lot of work
towards making it more ``jit-friendly'' including many more hints and even new
datastructures.

Especially when a bug cannot be reproduced on the untranslated interpreter,
debugging is difficult.

Translating even a restricted subset of Python to a much lower level language
like C is not an easy task. The RPython translator is thus a tangled web.

\end{aosasect1}

\begin{aosasect1}{A Note on Process}

In part to combat the complexity of PyPy (see section~\ref{sec:drawbacks}), PyPy
has adopted several so-called ``agile'' development methodologies. By far the
most important of these is test-driven development. All new features and bug
fixes are required to have a test to verify their correctness. PyPy's test
driver, py.test, was spun off and is now used in many other projects. PyPy also
has a continuous integration system that runs the test suite and translates the
interpreter on a variety of platforms. Binaries for all platforms are produced
daily and the benchmark suite is run.

There is a strong culture of experimentation in the PyPy project. Developers are
encouraged to make branches in the Mercurial repository. There, ideas in
development can be refined without destabilizing the main branch. Branches are
not always successful and our abandoned but if anything, PyPy developers are
tenacious. Most famously, the current PyPy JIT is the \emph{fith} attempt to add
a JIT to PyPy!

The PyPy project also prides itself on its visualization tools. The flow-graph
charts in section~\ref{sec:translator} are one example. PyPy also has tools to,
for example, show invocation of the garbage collector over time and regular
expression parse trees. Of special interest is jitviewer, a program allows that
one to visually peel pack the layers on a JITed function, from Python bytecode
to JIT IR to assembly.

\end{aosasect1}

\begin{aosasect1}{Conclusions}

The flexibility of (R)Python as an implementation language makes experimenting
with new language features (or even new languages) easy. At the same time, PyPy
is the fastest Python implementation today because of its JIT generator.

\end{aosasect1}

\end{aosachapter}
