\begin{aosachapter}{Git}{s:git}{Susan Potter}


\begin{aosasect1}{Git in a Nutshell}

Git enables the management of a digital body of work (often,
but not limited to, code) across a peer-to-peer network of
collaborating repositories. It supports distributed workflows to
manage a body of work that is either eventually converging or
diverging in nature. A feat not easily accomplished
using a centralized Version Control System (VCS).

This chapter will show how various aspects of Git work under the covers
to enable this and how this differs from centralized VCSes.

\end{aosasect1}

\begin{aosasect1}{Git's Origin}
To understand Git's design philosophy better it is helpful to understand the
circumstances from which the Git project was started in the Linux Kernel
community.

Git is an open source project that was born out of the needs and
frustrations of the Linux Kernel development community in 2005. At that time
the Linux kernel codebase had been managed across two VCS systems (BitKeeper
and CVS) for a few years already.

The Linux Kernel was first released in late 1991. It rapidly grew a
community of core developers and contributors by the mid-to-late 1990s. Along
side individuals adopting Linux there were organisations and teams of
developers creating Linux distributions based on top of the Linux Kernel
project by the close of the decade. These distributions would sometimes
temporarily fork the official version of the kernel if patches relevant to
their user base were not yet included in the Kernel codebase when releasing
new versions of their distribution thus essentially forking the project and
then merging upstream changes later on.

By the late 1990s Torvalds and other core developers voiced concerns
about managing patches from a large number of contributors for the
Kernel codebase using any of the open source VCSes available to them at
that time.

Between late 1999 and early 2005 many of the core developers of the Linux
Kernel opted to use BitKeeper, a proprietary distributed VCS made by
BitMover Inc. However, several key Linux Kernel developers (including Alan
Cox) refused to use BitKeeper, due to concerns over the proprietary Bitmover
license. By 2002 BitMover provided a way for the Linux BitKeeper servers to
interoperate with the Linux CVS server in a few ways. It offered a
public release and free use of its servers to a shortlist of free and
open source projects including the Linux Kernel. For a few years the
Linux Kernel would be maintained across two VCS systems in this way.

This ended during the first half of 2005, when BitMover retracted its
"Free Use" version for a number of key Linux Kernel developers and Git
was born to fill this void.

In April 2005, days after the BitMover announcement, Linus Torvalds began
development in haste of what was to become Git as we know it today. He began
by writing a collection of scripts to help him manage email patches to apply
one after the other. The aim of this initial collection of scripts was to
fail merges quickly so the maintainer could modify the codebase mid-patch
stream and continue merging contributed patches once cleanly able to.

Torvald's had one philosphical goal for Git - to embody the anti-CVS - plus
three usability design goals from the outset:
\begin{aosaitemize}
  \item support distributed workflows like those enabled by BitKeeper
  \item offer safeguards against content corruption
  \item offer high performance
\end{aosaitemize}

These design goals have been accomplished and maintained as I will attempt
to show when dissecting Git's use of DAGs for content storage, reference
pointers for heads, object model representatation, remote protocol and how
it tracks the merging of trees.

Despite BitKeeper influencing the original design of Git, it is implemented
in fundamentally different ways and allows even more distributed and even
local-only workflows, which weren't possible with BitKeeper, which requires
at least one server.

Around this time (c2005) three other open source distributed VCS projects
were initiated, including Mercurial, which is a project covered in volume 1
of this title series. All of these dCVS tools offer slightly different ways
to enable distributed workflows, which centralized VCS systems before them
were not capable for handling directly. \emph{Note: Subversion has an
extension maintained by different developers to support server-to-server
synchronization named SVK.}

\end{aosasect1}

\begin{aosasect1}{Version Control System (VCS) Landscape}

Now is a good time to take a step back and look at the alternative VCS
solutions to Git. Understanding these differences will allow us to explore
the architectural choices made while developing Git.

DIAGRAM

There are three primary distribution modes for VCSes: local, client/server
and distributed (or peer-to-peer). Some VCSes can support all of these, some
just one.

On the other axis we can see two primary categories for storage modes:
delta based and directed acyclic graph based.

We can see, from the diagram, that Git is a VCS that can support local,
client/server and peer-to-peer distribution modes and uses DAG based content
storage.

As mentioned previously in this chapter, Git is a distributed VCS. What does
this mean?

On a fundamental level it means that a \emph{work} does not \emph{need} to
have a centralized, all-knowing repository that will be the only source of
truth for the \emph{work}. However, that doesn't prevent us for using it in
this way if we so wish to do so. Though it still may not behave exactly like
some of the centralized VCS solutions you might be familiar with already.

At the heart of every VCS tool is tracking the history of an evolving
\emph{work}. The Revision Control System (RCS) was one of the first popular
VCSes. It was based on tracking revisions of individual files taking care of
storing, retrieving, logging, identifying, and merging revisions. It offered
a number of improvements over the more primitive VCS it was based on,
Source Code Control System (SCCS). It did this by providing an easier
interface and improving performance of retrieving versions for its primary
use case. The Concurrent Versions System (CVS) was built on top of RCS adding
a client/server model, which made sharing changes of the work on a team more
tenable than its predecessor. Subversion was CVS's successor, which added
better support for renaming files/folders and also dropped first class
support of trunking and tags, opting instead for an unenforced repository
directory structure convention. Subversion continued CVS's centralized
client/server approach, however.

This VCS product family only support linear histories. Where later
versions supercede earlier versions. Git is not part of this family; there is
no easy conceptual evolution from Subversion to Git in terms of tracking
histories or content.

\aosafigure{../images/git/dag-example.png}{Example of a DAG representation
  in Git}{fig.git.dag}

Instead Git enables full branching capability using directed acyclic
graphs (DAG) to store content. The history of a file is linked all the way
up its directory structure (via nodes representing directories) to the root
directory, which is then linked to a commit node. This commit node in turn
can have one or more parents (more on this later). This affords us two
properties that allow us to reason about our history and content in
more definite ways than the RCS family. Namely:
\begin{aosaitemize}
  \item When a content (file or directory) node in the graph has the same
  reference identity (the SHA in Git) as that in a different commit, the two
  nodes are guaranteed to contain the same content. Allowing Git to
  short-circuit content diffing efficiently.
  \item When merging two branches we are merging the content of two nodes
  in a DAG. The DAG allows Git to "efficiently" (as compared to the
  RCS family of VCS approach) determine common ancestors.
\end{aosaitemize}

\end{aosasect1}

\begin{aosasect1}{The Toolkit}

Today the Git ecosystem posesses many GUIs on a number of operating systems.
These are mostly built on top of the Git core toolkit.

Due to the way Git was originally written by Linus and its inception within
the Linux community it was written with a toolkit design philosphy very much
in the Unix tradition of command line tools.

The Git toolkit is divided into two parts: the plumbing and
the porcelain. The plumbing consists of low-level commands that enable
the manipulation of directed acyclic graphs (DAG) and basic content
tracking. The porcelain is the smaller subset of git commands that most
end-users of Git are likely to need to use for maintaining repositories and
communicating between repositories for collaboration.

While the toolkit design has provided enough commands to offer fine grained
access to functionality for many scripters, application developers
complained about the lack of a linkable library for Git. Since the Git binary
calls die(), it was not reentrant and GUIs, web interfaces or longer running
services would have to fork/exec a call to the Git binary, which can be slow.

Shawn Pearce spearheaded an effort to create a linkable Git library with
more permissive licensing that didn't inhibit use of the library. This was
called libgit2. It didn't find much traction until a student named, Vincent
Marti chose it for his Google Summer of Code project last year. Since then
Vincent and GitHub have continued contributing to the libgit2 project and
created Ruby bindings for it in a project called Rugged. More recently
Python bindings around libgit2 have emerged in an open source project
called pygit2. These three open source projects are maintained independently
of the Git core project.

As you can see today there is a wide array of ways to integrate with Git.
From the plumbing portion of the toolkit, procelain layer and now the
linkable library, libgit2 and its offshoots.
\end{aosasect1}

\begin{aosasect1}{The Repository, Index and Working Areas}

Let us get our hands dirty and dive into using Git locally, if only to
understand a few fundamental concepts.

First to create a new initialized Git repository on our local filesystem
(using a Unix inspired operating system) we can do:
\begin{aosaitemize}
  \item \code{mkdir testgit}
  \item \code{cd testgit}
  \item \code{git init}
\end{aosaitemize}

Now we have an empty, but initialized Git repository sitting in our testgit
directory. We can branch, commit, tag and even communicate with other local
and remote Git repositories. Even communication with other types of VCS
repositories is possible with just a handful of \code{git} commands.

The \code{git init} command creates a .git subdirectory inside of testgit.
Let us have a peak inside of it:
\begin{aosaitemize}
  \item \code{tree .git/}\newline
  \code{
.git/\newline
|-- HEAD\newline
|-- config\newline
|-- description\newline
|-- hooks\newline
|   |-- applypatch-msg.sample\newline
|   |-- commit-msg.sample\newline
|   |-- post-commit.sample\newline
|   |-- post-receive.sample\newline
|   |-- post-update.sample\newline
|   |-- pre-applypatch.sample\newline
|   |-- pre-commit.sample\newline
|   |-- pre-rebase.sample\newline
|   |-- prepare-commit-msg.sample\newline
|   |-- update.sample\newline
|-- info\newline
|   |-- exclude\newline
|-- objects\newline
|   |-- info\newline
|   |-- pack\newline
|-- refs\newline
    |-- heads\newline
    |-- tags\newline
}
\end{aosaitemize}

The .git directory above is by default a subdirectory of the root working
directory, testgit. It contains a few different types of files and
directories:

\begin{aosaitemize}
  \item \emph{Configuration}: the .git/config, .git/description and
  .git/info/exclude files essentially help configure the local repository.
  \item \emph{Hooks}: the .git/hooks directory contains scripts that can
  be run on certain lifecycle events of the repository.
  \item \emph{Staging Area}: the .git/index file (which is not yet
  present in our tree listing above) will provide a staging area for our
  working directory.
  \item \emph{Object Database}: the .git/objects directory is the default
  Git object database, which contains all content or pointers to local
  content. All objects are immutable once created.
  \item \emph{References}: the .git/refs directory is the default location
  for storing reference pointers for both local and remote branches, tags and
  heads. A reference is a pointer to an object, usually of type \emph{tag} or
  \emph{commit}. References are managed outside of the Object Database to
  allow the references to change where they point to as the repository
  evolves. Special cases of references may point to other references, e.g.
  \code{HEAD}.
\end{aosaitemize}

This is the actual repository. The directory that contains the working set
of files is the \emph{working directory}, which is typically the parent of
the .git directory (or \emph{repository}). If you were creating a Git
remote repository that wouldn't have a working directory you could
initialize it using the \code{git init --bare} command. This would create
just the pared down repository files at the root, instead of creating it
as a subdirectory under the working tree.

Another file of great importance is the \emph{Git index}. It provides the
staging area between the local working directory and the local repository.
The index is used to stage specific changes within a file (or more) to
be committed all together. Even if you make changes related to various types
of features, the commits can be made with like changes together to more
logically describe them in the commit message. To selectively stage
specific changes in a file or set of files you can using \code{git add -p}.

The \emph{Git index}, by default, is stored as a single file inside the
repository directory. The paths to these three areas can be customized
using the following environment variables:
\begin{aosaitemize}
  \item \code{GIT\_DIR}: sets the repository directory or the \emph{.git}
  directory.
  \item \code{GIT\_INDEX}: sets the path to the \emph{index}. This is often
  referred to as the staging area as well.
  \item \code{GIT\_WORK\_DIR}: sets the path to the \emph{working directory}
  for the local Git repository. The work directory represents the "live"
  state of the current head (or HEAD) of the Git repository. This is usually
  a reference to the current branch.
\end{aosaitemize}

It is helpful to understand the interactions that take place between these
three areas (the repository, index and working areas) during the execution
of a few core Git commands:

\begin{aosaitemize}
  \item \code{git checkout [branch]} \newline
  \small{This will move the HEAD reference of the local repository to branch
  reference path (e.g. \code{refs/heads/master}), populate the index with
  this head data and refresh the working directory to represent the tree
  at that head.}
  \item \code{git add [files]} \newline
  \small{This will cross reference the checksums of the \emph{files}
  specified with the corresponding entries in the Git index to see if the
  index for staged files needs updating with the working directory's
  version. Nothing changes in the Git directory (or repository).}
\end{aosaitemize}

Let us explore what this means more concretely by inspecting the contents of
files under the .git directory (or repository).

\begin{aosaitemize}
  \item \code{GIT\_DIR=\${PWD}/.git}
  \item \code{cat \${GIT\_DIR}/HEAD}
\begin{verbatim}
ref: refs/heads/master
\end{verbatim}
  \item \code{MY\_CURRENT\_BRANCH=\$(cat .git/HEAD | sed 's/ref: //g')}
  \item \code{cat \${GIT\_DIR}/\${MY\_CURRENT\_BRANCH}}
\begin{verbatim}
cat: .git/refs/heads/master: No such file or directory
\end{verbatim}
\end{aosaitemize}

We get an error because, before making any commits to a Git repository at
all, no branches exist, except the default branch in Git is \code{master},
whether it exists yet or not.

We can verify that no branches exist yet by attempting to list the branches
in our repository with \code{git branch}.

Now if we make a new commit then the master branch is created by default for
this commit. Let us do this (continuing in the same shell, retaining
history and context):

\begin{aosaitemize}
  \item \code{git commit -m "Initial empty commit" --allow-empty}
  \item \code{git branch}
\begin{verbatim}
* master
\end{verbatim}
  \item \code{cat \${GIT\_DIR}/\${MY\_CURRENT\_BRANCH}}
\begin{verbatim}
3bce5b130b17b7ce2f98d17b2998e32b1bc29d68
\end{verbatim}
  \item \code{git cat-file -p \$(cat \${GIT\_DIR}/\${MY\_CURRENT\_BRANCH})}
\end{aosaitemize}

What we are starting to see here is the content representation inside Git's
object database.

Let us explore what this means more concretely by inspecting the contents of
files under the .git directory (or repository).

\begin{aosaitemize}
  \item \code{GIT\_DIR=\${PWD}/.git}
  \item \code{cat \${GIT\_DIR}/HEAD}
\begin{verbatim}
ref: refs/heads/master
\end{verbatim}
  \item \code{MY\_CURRENT\_BRANCH=\$(cat .git/HEAD | sed 's/ref: //g')}
  \item \code{cat \${GIT\_DIR}/\${MY\_CURRENT\_BRANCH}}
\begin{verbatim}
cat: .git/refs/heads/master: No such file or directory
\end{verbatim}
\end{aosaitemize}

We get an error because, before making any commits to a Git repository at
all, no branches exist, except the default branch in Git is \code{master},
whether it exists yet or not.

We can verify that no branches exist yet by attempting to list the branches
in our repository with \code{git branch}.

Now if we make a new commit then the master branch is created by default for
this commit. Let us do this (continuing in the same shell, retaining
history and context):

\begin{aosaitemize}
  \item \code{git commit -m "Initial empty commit" --allow-empty}
  \item \code{git branch}
\begin{verbatim}
* master
\end{verbatim}
  \item \code{cat \${GIT\_DIR}/\${MY\_CURRENT\_BRANCH}}
\begin{verbatim}
3bce5b130b17b7ce2f98d17b2998e32b1bc29d68
\end{verbatim}
  \item \code{git cat-file -p \$(cat \${GIT\_DIR}/\${MY\_CURRENT\_BRANCH})}
\end{aosaitemize}

What we are starting to see here is the content representation inside Git's
object database.

\end{aosasect1}

\begin{aosasect1}{The Object Database}

\aosafigure{../images/git/object-hierarchy.png}{Git Objects}{fig.git.objects}

Git has four basic primitive objects that every type of content in the
local repository is built around. Each object type has the following
attributes: \emph{type}, \emph{size} and \emph{content}. The primitive object
types are:
\begin{aosaitemize}
  \item \emph{Tree}: elements in a tree can be another tree or a blob when
  representing a content directory.
  \item \emph{Blob}: a blob represents a file stored in the repository.
  \item \emph{Commit}: a commit points to a tree representing the top level
  directory for that commit as well as parent commits and standard
  attributes.
  \item \emph{Tag}: a tag has a name and points to a commit at the point in
  the repository history that the tag represents
\end{aosaitemize}

All object primitives are referenced by a SHA, a 40-digit object identity,
which has the following properties:
\begin{aosaitemize}
  \item if two objects are identical they will have the same SHA
  \item if two objects are different they will have different SHAs
  \item if an object was only copied partially or another form of data
        corruption occurred, recalculating the SHA of the current object
        will identify such corruption
\end{aosaitemize}

The first two properties of the SHA relating to identity of the objects is
most useful to enable Git's distributed model (the second goal of Git).
The latter property enables some safegaurds against corruption (the third
goal of Git above).

Despite the desirable properties of using DAG based storage for content
storage and merge histories, for many repositories delta storage will be
more space efficient than using \emph{loose} DAG objects.

\end{aosasect1}

\begin{aosasect1}{Storage and Compression Techniques}

Git tackles the storage space problem by "packing" objects in a compressed
format using an index file to point to offsets to specific objects in the
corresponding \emph{packed} file.

\aosafigure{../images/git/packed-format.png}{Diagram of a pack file with
  corresponding index file}{fig.git.pack}

We can count the number of \emph{loose} (or unpacked) objects in the local
Git repository using \code{git count-objects}. Now we can have Git pack
\emph{loose} objects in the object database using \code{git repack}. Now we
can ask Git to remove loose objects already packed using
\code{git prune-packed}. We can also find redundant pack files in our local
repository using \code{git pack-redundant}.

On a small sized repository with commits in the order of 100 and number of
files (or blobs) also in the order of 100 you might see output that looks
like the following:

\begin{aosaitemize}
  \item \code{git repack} \newline
\begin{verbatim}Counting objects: 800, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (792/792), done.
Writing objects: 100% (800/800), done.
Total 800 (delta 358), reused 0 (delta 0)\end{verbatim}
  \item \code{git count-objects} \newline
\begin{verbatim}817 objects, 9004 kilobytes\end{verbatim}
  \item \code{git prune-packed}
  \item \code{git count-objects} \newline
\begin{verbatim}17 objects, 88 kilobytes\end{verbatim}
  \item \code{git pack-redundant} \newline
\begin{verbatim}fatal: Zero packs found!\end{verbatim}
\end{aosaitemize}

There are two versions of pack files as of this writing: version 1 and
version 2. Version 1 being used in versions of Git before version 1.6 of Git
and version 2 of the pack file format being used by default in version 1.6
and above of Git.

In version 1 of the pack file format in Git, only CRC checksums for
the pack file and index file are stored in the index file. This means there
is the possibility of undetectable corruption in the compressed data during
the repacking phase without any further checks. Version 2 of the pack file
format overcomes this problem by including the CRC checksums of each
compressed object in the pack index file. Version 2 also allows packfiles
larger than 4 Gb, which version 1 does not support. As a way to quickly
detect pack file corruption the end of the pack file contains a 20-byte SHA1
sum of the ordered list of all the SHAs in that file.

The emphasis of the newer pack file format is to help fulfill Git second
usability design goal of offering safegaurds against data corruption.

\end{aosasect1}

\begin{aosasect1}{Merge Histories}

As mentioned previously Git differs fundamentally in merge history approach
than the RCS family of VCSes. Subversion, for example, represents
file or tree history has a linear progression. Whatever has a higher revision
number will supercede anything before it. Branching isn't supported directly,
only through an unenforced directory structure within the repository.

Let us use an example to show how this can be problematic when maintaining
multiple branches of a work. When working on a "branch" in Subversion at the
typical root \code{branches/branch-name}, we are working on directory
subtree adjacent to the \code{trunk} (typically where the live or
\emph{master} equivalent code resides within). Let us say this branch is
to represent parallel development of the \code{trunk} tree.

As an example,
we might be rewriting a codebase to use a different database. Part of the
way through our rewrite we wish to merge in upstream changes from the
\code{trunk} subtree. We merge in these changes, manually if necessary, and
proceed with our rewrite. The problem with the way linear history VCSes like
Subversion handle this is that there is no way to know which changesets have
been merged into this branch from other branches via the changeset history
built in to the tool.

\end{aosasect1}

\begin{aosasect1}{Remote Communication}


\end{aosasect1}

\begin{aosasect1}{Future Work}

TODO/NOTES:
Discuss the work being done now on using different object database backends
for storage, from Redis, Memcached, SQLite and others.

\end{aosasect1}

\end{aosachapter}
